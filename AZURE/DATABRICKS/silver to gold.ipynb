{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6f6f9f7-1bcc-48f4-8f31-0ba2179b1d6a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from delta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62ca6eee-b1df-4d3a-80c7-d7ed1f0fb0cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dim_date = \"gold.DIM_DATES\"\n",
    "dim_user = \"gold.DIM_USERS\"\n",
    "dim_vehicle = \"gold.DIM_VEHICLES\"\n",
    "dim_location = \"gold.DIM_LOCATIONS\"\n",
    "fact_request = \"gold.FCT_REQUESTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b02520e-1404-46e6-b463-eb5b8d34e02a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- location_id: integer (nullable = true)\n |-- longitude: decimal(12,8) (nullable = true)\n |-- latitude: decimal(12,8) (nullable = true)\n |-- processing_date: timestamp (nullable = true)\n |-- record_modified_date: timestamp (nullable = true)\n |-- record_hash: string (nullable = true)\n\nroot\n |-- payment_id: integer (nullable = true)\n |-- payment_method_id: integer (nullable = true)\n |-- payment_status_id: integer (nullable = true)\n |-- processing_date: timestamp (nullable = true)\n |-- record_modified_date: timestamp (nullable = true)\n |-- record_hash: string (nullable = true)\n\nroot\n |-- payment_method_id: integer (nullable = true)\n |-- method_name: string (nullable = true)\n |-- processing_date: timestamp (nullable = true)\n |-- record_modified_date: timestamp (nullable = true)\n |-- record_hash: string (nullable = true)\n\nroot\n |-- payment_status_id: integer (nullable = true)\n |-- status_name: string (nullable = true)\n |-- processing_date: timestamp (nullable = true)\n |-- record_modified_date: timestamp (nullable = true)\n |-- record_hash: string (nullable = true)\n\nroot\n |-- request_id: integer (nullable = true)\n |-- passenger_id: integer (nullable = true)\n |-- pickup_location_id: integer (nullable = true)\n |-- dropoff_location_id: integer (nullable = true)\n |-- request_time: timestamp (nullable = true)\n |-- accept_time: timestamp (nullable = true)\n |-- processing_date: timestamp (nullable = true)\n |-- record_modified_date: timestamp (nullable = true)\n |-- record_hash: string (nullable = true)\n\nroot\n |-- trip_id: integer (nullable = true)\n |-- request_id: integer (nullable = true)\n |-- driver_id: integer (nullable = true)\n |-- vehicle_id: integer (nullable = true)\n |-- payment_id: integer (nullable = true)\n |-- trip_start_time: timestamp (nullable = true)\n |-- trip_end_time: timestamp (nullable = true)\n |-- trip_distance: decimal(10,2) (nullable = true)\n |-- base_fare: decimal(10,2) (nullable = true)\n |-- extra_fare: decimal(10,2) (nullable = true)\n |-- mta_tax: decimal(10,2) (nullable = true)\n |-- tip_amount: decimal(10,2) (nullable = true)\n |-- tolls_amount: decimal(10,2) (nullable = true)\n |-- improvement_surcharge: decimal(10,2) (nullable = true)\n |-- processing_date: timestamp (nullable = true)\n |-- record_modified_date: timestamp (nullable = true)\n |-- record_hash: string (nullable = true)\n\nroot\n |-- user_id: integer (nullable = true)\n |-- full_name: string (nullable = true)\n |-- email: string (nullable = true)\n |-- phone_number: string (nullable = true)\n |-- processing_date: timestamp (nullable = true)\n |-- record_modified_date: timestamp (nullable = true)\n |-- record_hash: string (nullable = true)\n\nroot\n |-- make_id: integer (nullable = true)\n |-- make_name: string (nullable = true)\n |-- processing_date: timestamp (nullable = true)\n |-- record_modified_date: timestamp (nullable = true)\n |-- record_hash: string (nullable = true)\n\nroot\n |-- vehicle_id: integer (nullable = true)\n |-- driver_id: integer (nullable = true)\n |-- make_id: integer (nullable = true)\n |-- model: string (nullable = true)\n |-- year: integer (nullable = true)\n |-- color: string (nullable = true)\n |-- license_plate: string (nullable = true)\n |-- processing_date: timestamp (nullable = true)\n |-- record_modified_date: timestamp (nullable = true)\n |-- record_hash: string (nullable = true)\n\n+-------+------------------+--------------------+--------------+-------------------+--------------------+--------------------+\n|user_id|         full_name|               email|  phone_number|    processing_date|record_modified_date|         record_hash|\n+-------+------------------+--------------------+--------------+-------------------+--------------------+--------------------+\n| 941101|      Roger Steele|hreynolds@example...|(422) 748-8842|2024-10-15 00:12:56| 2024-10-14 15:48:30|00002092f76429912...|\n| 986608|       Wendy Adams|johnsonaustin@exa...|(269) 318-9123|2024-10-15 00:12:56| 2024-10-14 15:48:30|00007bfccf7e03681...|\n| 805716|      Howard Lucas|candice63@example...|(253) 757-7081|2024-10-15 00:12:56| 2024-10-14 15:48:30|0000d60cfa952b0ae...|\n| 833097|      Joel Stanton|hugheschristina@e...|(554) 565-2140|2024-10-15 00:12:56| 2024-10-14 15:48:30|0000d9d11f26dab80...|\n| 152981|Katherine Martinez|berrymonica@examp...|(485) 667-5677|2024-10-15 00:12:56| 2024-10-14 15:48:30|0001071191e995700...|\n| 179415|        Lori Short|torreskimberly@ex...|(832) 437-3476|2024-10-15 00:12:56| 2024-10-14 15:48:30|0001977a81c999214...|\n| 814560|     Janet Kennedy|keithcaitlin@exam...|(603) 106-8854|2024-10-15 00:12:56| 2024-10-14 15:48:30|00019d097cb1bddbe...|\n| 102042|    Hannah Mcmahon| derek38@example.net|(754) 881-4212|2024-10-15 00:12:56| 2024-10-14 15:48:30|0001d949b916f6f12...|\n| 962891|    Steven Barajas|lopezbryan@exampl...|(485) 160-4550|2024-10-15 00:12:56| 2024-10-14 15:48:30|0002275e0a12eeae6...|\n| 814526|      Janet Howard|devinwilson@examp...|(144) 904-4214|2024-10-15 00:12:56| 2024-10-14 15:48:30|0002294378e66c579...|\n| 816802|         Jason Kim|sandraduncan@exam...|(847) 131-3030|2024-10-15 00:12:56| 2024-10-14 15:48:30|0002670c30ead0cf0...|\n| 870423|      Laura Jordan|johnsonclifford@e...|(626) 429-1649|2024-10-15 00:12:56| 2024-10-14 15:48:30|0002e865085988a33...|\n| 218300|     Nicole Dalton|crystal84@example...|(797) 793-2135|2024-10-15 00:12:56| 2024-10-14 15:48:30|0002fff5f4c82173a...|\n| 713058|        Ana Butler|leetimothy@exampl...|(563) 377-6105|2024-10-15 00:12:56| 2024-10-14 15:48:30|0003357be0d9e08f0...|\n|  50715| Christina Johnson|gailhernandez@exa...|(937) 997-7898|2024-10-15 00:12:56| 2024-10-14 15:48:30|0003508d189087872...|\n| 916879|   Nicholas Flores|  dsmith@example.net|(307) 650-8505|2024-10-15 00:12:56| 2024-10-14 15:48:30|000372e2bdbf888a5...|\n| 782463|    Douglas Torres| kevin07@example.org|(835) 947-5082|2024-10-15 00:12:56| 2024-10-14 15:48:30|0003e0890e65adb20...|\n| 799805|      Gloria Craig|jacobcarter@examp...|(505) 882-5700|2024-10-15 00:12:56| 2024-10-14 15:48:30|00047d4c91f850e54...|\n|    564|  Aaron Mccullough|herrerajack@examp...|(684) 361-3743|2024-10-15 00:12:56| 2024-10-14 15:48:30|0004a407b412e48db...|\n| 128768|Jessica Jacobs DDS|  msmith@example.com|(354) 100-9802|2024-10-15 00:12:56| 2024-10-14 15:48:30|0004c079c97f7f0dc...|\n+-------+------------------+--------------------+--------------+-------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Get the list of tables in the specified schema\n",
    "tables = spark.sql(\"SHOW TABLES IN silver\").collect()\n",
    "# Dictionary to store DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Loop through each table in the schema\n",
    "for row in tables:\n",
    "    table_name = row['tableName']  # Get the table name\n",
    "    full_table_name = f\"silver.{table_name}\"  # Construct the full table name\n",
    "    # Read the data and filter based on the current date\n",
    "    df = spark.read.table(full_table_name)\n",
    "    df.printSchema()  # Check the schema of the DataFrame\n",
    "\n",
    "    df = spark.read.table(full_table_name).filter(to_date(col(\"processing_date\")) == current_date())\n",
    "    # Store the DataFrame in the dictionary\n",
    "    dataframes[full_table_name.split('.')[1]] = df\n",
    "\n",
    "# Example: Show the first few rows of a specific DataFrame (e.g., user)\n",
    "if \"user\" in dataframes:\n",
    "    dataframes[\"user\"].show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2125108b-05f9-442d-a592-530ff2480635",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------------------+--------------+-------------------+--------------------+--------------------+\n|user_id|      full_name|               email|  phone_number|    processing_date|record_modified_date|         record_hash|\n+-------+---------------+--------------------+--------------+-------------------+--------------------+--------------------+\n| 700001|   Aaron Abbott|angela67@example.com|(453) 832-3608|2024-10-15 00:12:56| 2024-10-14 15:48:30|6e1ef69ae8734c534...|\n|      1|   Aaron Acosta| vbishop@example.net|(677) 367-9557|2024-10-15 00:12:56| 2024-10-14 15:48:30|21d31195f82942e05...|\n| 700002|   Aaron Acosta|vanessa20@example...|(953) 599-6007|2024-10-15 00:12:56| 2024-10-14 15:48:30|62d5bc8c4ecbeaf3d...|\n|      4|    Aaron Adams|zjohnson@example.com|(324) 384-5822|2024-10-15 00:12:56| 2024-10-14 15:48:30|60f62b9afaac9bbb8...|\n| 700006|    Aaron Adams| emily69@example.net|(217) 156-8782|2024-10-15 00:12:56| 2024-10-14 15:48:30|4866e617e54ca7de7...|\n|      2|    Aaron Adams| james82@example.com|(332) 224-7965|2024-10-15 00:12:56| 2024-10-14 15:48:30|683e6c22fa1e45bef...|\n| 700007|    Aaron Adams|jesseschwartz@exa...|(250) 242-4652|2024-10-15 00:12:56| 2024-10-14 15:48:30|09f0d6b77ee353721...|\n| 700008|    Aaron Adams|  jill51@example.org|(120) 200-5627|2024-10-15 00:12:56| 2024-10-14 15:48:30|2136a8fcbeb5a2344...|\n|      3|    Aaron Adams|nicholas92@exampl...|(351) 943-8670|2024-10-15 00:12:56| 2024-10-14 15:48:30|500bf842d2becc183...|\n| 700005|    Aaron Adams|  dbowen@example.net|(672) 995-6696|2024-10-15 00:12:56| 2024-10-14 15:48:30|95bcf56ae7d7d1a85...|\n| 700003|    Aaron Adams|angela64@example.com|(619) 154-2732|2024-10-15 00:12:56| 2024-10-14 15:48:30|c5cb6cb18f3c64b7d...|\n| 700004|    Aaron Adams|beckdaniel@exampl...|(987) 878-1073|2024-10-15 00:12:56| 2024-10-14 15:48:30|d419e2eef5018e4d7...|\n| 700009|   Aaron Adkins|   jchan@example.com|(959) 936-7702|2024-10-15 00:12:56| 2024-10-14 15:48:30|64243d430f017b27b...|\n|      5|  Aaron Aguilar|anthony78@example...|(867) 762-3031|2024-10-15 00:12:56| 2024-10-14 15:48:30|a966dd203faf1291c...|\n|      6|  Aaron Aguilar|wilsonruben@examp...|(376) 707-8408|2024-10-15 00:12:56| 2024-10-14 15:48:30|7d403c55cd6dae43e...|\n| 700011|  Aaron Aguilar|reyeselizabeth@ex...|(554) 632-2702|2024-10-15 00:12:56| 2024-10-14 15:48:30|6b3dc250c9028f67b...|\n| 700010|  Aaron Aguilar|beverlyhale@examp...|(862) 346-3495|2024-10-15 00:12:56| 2024-10-14 15:48:30|9da28f3e6bf59f72f...|\n|      7|  Aaron Aguirre|samantha45@exampl...|(147) 383-2497|2024-10-15 00:12:56| 2024-10-14 15:48:30|e67e82d0ddd8f2482...|\n| 700014|Aaron Alexander|mercadoerin@examp...|(527) 635-4032|2024-10-15 00:12:56| 2024-10-14 15:48:30|1639c1f9be36ddcc4...|\n| 700012|Aaron Alexander|jasonhanna@exampl...|(868) 281-9704|2024-10-15 00:12:56| 2024-10-14 15:48:30|02ad6af82b5132694...|\n+-------+---------------+--------------------+--------------+-------------------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "dataframes[\"user\"].orderBy(\"full_name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "603c5039-d0fa-46d4-aedc-a6187e501059",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Join user_df with vehicle_df on user_id (assuming driver_id in vehicle_df relates to user_id)\n",
    "user_vehicle_df = dataframes[\"user\"].join(dataframes[\"vehicles\"], dataframes[\"user\"][\"user_id\"] == dataframes[\"vehicles\"][\"driver_id\"], \"left\")\n",
    "\n",
    "# Step 2: Join vehicle_df with vehicle_make_df on make_id to bring in make details\n",
    "user_vehicle_make_df = user_vehicle_df.join(dataframes[\"vehiclemakes\"], dataframes[\"vehicles\"][\"make_id\"] == dataframes[\"vehiclemakes\"][\"make_id\"], \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ca28a3a-ccc2-4871-b6e7-d3db4b24c7fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dim_user = user_vehicle_make_df.select(\n",
    "    \"user_id\",\n",
    "    \"full_name\",\n",
    "    \"email\",\n",
    "    \"phone_number\",\n",
    "    # Replace NULLs in vehicle columns with 'Passenger' or 'N/A'\n",
    "    coalesce(user_vehicle_make_df[\"vehicle_id\"], lit(\"Passenger\")).alias(\"vehicle_id\"),\n",
    "    coalesce(user_vehicle_make_df[\"make_name\"], lit(\"Passenger\")).alias(\"vehicle_make\"),\n",
    "    coalesce(user_vehicle_make_df[\"model\"], lit(\"Passenger\")).alias(\"vehicle_model\"),\n",
    "    coalesce(user_vehicle_make_df[\"year\"], lit(\"Passenger\")).alias(\"vehicle_year\"),\n",
    "    coalesce(user_vehicle_make_df[\"color\"], lit(\"Passenger\")).alias(\"vehicle_color\"),\n",
    "    coalesce(user_vehicle_make_df[\"license_plate\"], lit(\"Passenger\")).alias(\"vehicle_license_plate\")\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9112f9e-73d4-4ee3-9d48-c03d43aecf73",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------------------+--------------+----------+-------------+-------------+------------+-------------+---------------------+\n|user_id|      full_name|               email|  phone_number|vehicle_id| vehicle_make|vehicle_model|vehicle_year|vehicle_color|vehicle_license_plate|\n+-------+---------------+--------------------+--------------+----------+-------------+-------------+------------+-------------+---------------------+\n| 700001|   Aaron Abbott|angela67@example.com|(453) 832-3608|    168434|      Hyundai|     Santa Fe|        2006|       Silver|              3BW 116|\n|      1|   Aaron Acosta| vbishop@example.net|(677) 367-9557| Passenger|    Passenger|    Passenger|   Passenger|    Passenger|            Passenger|\n| 700002|   Aaron Acosta|vanessa20@example...|(953) 599-6007|     11618|          BMW|     5 Series|        2017|       Orange|                 389J|\n|      4|    Aaron Adams|zjohnson@example.com|(324) 384-5822| Passenger|    Passenger|    Passenger|   Passenger|    Passenger|            Passenger|\n| 700006|    Aaron Adams| emily69@example.net|(217) 156-8782|     67661|    Chevrolet|        Tahoe|        1994|         Blue|              YCF 385|\n|      2|    Aaron Adams| james82@example.com|(332) 224-7965| Passenger|    Passenger|    Passenger|   Passenger|    Passenger|            Passenger|\n| 700007|    Aaron Adams|jesseschwartz@exa...|(250) 242-4652|     91967|         Ford|        F-150|        2017|         Gray|             50-41182|\n| 700008|    Aaron Adams|  jill51@example.org|(120) 200-5627|    138962|        Honda|          Fit|        2006|       Silver|              65M 278|\n|      3|    Aaron Adams|nicholas92@exampl...|(351) 943-8670| Passenger|    Passenger|    Passenger|   Passenger|    Passenger|            Passenger|\n| 700005|    Aaron Adams|  dbowen@example.net|(672) 995-6696|     23039|          BMW|           X5|        1996|         Blue|              IIV-491|\n| 700003|    Aaron Adams|angela64@example.com|(619) 154-2732|    359266|   Volkswagen|       Passat|        1997|        Green|              SRO 232|\n| 700004|    Aaron Adams|beckdaniel@exampl...|(987) 878-1073|     52562|    Chevrolet|       Malibu|        2022|        Black|              324 JEN|\n| 700009|   Aaron Adkins|   jchan@example.com|(959) 936-7702|    194019|          Kia|       Optima|        2005|         Blue|              VJP4675|\n|      5|  Aaron Aguilar|anthony78@example...|(867) 762-3031| Passenger|    Passenger|    Passenger|   Passenger|    Passenger|            Passenger|\n|      6|  Aaron Aguilar|wilsonruben@examp...|(376) 707-8408| Passenger|    Passenger|    Passenger|   Passenger|    Passenger|            Passenger|\n| 700011|  Aaron Aguilar|reyeselizabeth@ex...|(554) 632-2702|    229699|Mercedes-Benz|      E-Class|        1994|        Black|              6-13526|\n| 700010|  Aaron Aguilar|beverlyhale@examp...|(862) 346-3495|    102860|         Ford|       Fusion|        2012|        White|             86-85485|\n|      7|  Aaron Aguirre|samantha45@exampl...|(147) 383-2497| Passenger|    Passenger|    Passenger|   Passenger|    Passenger|            Passenger|\n| 700014|Aaron Alexander|mercadoerin@examp...|(527) 635-4032|    209533|          Kia|         Soul|        2010|        Brown|              172 0QC|\n| 700012|Aaron Alexander|jasonhanna@exampl...|(868) 281-9704|    191874|          Kia|        Forte|        2011|        White|             0Z W8141|\n+-------+---------------+--------------------+--------------+----------+-------------+-------------+------------+-------------+---------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "dim_user.orderBy(\"full_name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d806e5b4-7195-44c5-a01f-01588479758a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- date_key: string (nullable = false)\n |-- full_date: date (nullable = false)\n |-- day: integer (nullable = false)\n |-- day_name: string (nullable = false)\n |-- day_of_week: integer (nullable = false)\n |-- week_of_year: integer (nullable = false)\n |-- month: integer (nullable = false)\n |-- month_name: string (nullable = false)\n |-- quarter: integer (nullable = false)\n |-- year: integer (nullable = false)\n |-- is_weekend: integer (nullable = false)\n |-- is_holiday: integer (nullable = false)\n |-- fiscal_month: integer (nullable = false)\n |-- fiscal_quarter: integer (nullable = false)\n |-- fiscal_year: integer (nullable = false)\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the start and end date\n",
    "start_date = \"2015-01-01\"\n",
    "end_date = \"2015-01-31\"\n",
    "\n",
    "# Create a Spark DataFrame with a date range using the sequence function\n",
    "calendar_df = spark.sql(f\"\"\"\n",
    "    SELECT explode(sequence(to_date('{start_date}'), to_date('{end_date}'), interval 1 day)) as full_date\n",
    "\"\"\")\n",
    "\n",
    "# Transform the DataFrame to create the calendar dimension\n",
    "dim_calendar = calendar_df.select(\n",
    "    date_format(\"full_date\", \"yyyyMMdd\").alias(\"date_key\"),  # Convert to string format YYYYMMDD\n",
    "    col(\"full_date\"),\n",
    "    dayofmonth(\"full_date\").alias(\"day\"),  # Day of the month\n",
    "    date_format(\"full_date\", \"EEEE\").alias(\"day_name\"),  # Full name of the day\n",
    "    dayofweek(\"full_date\").alias(\"day_of_week\"),  # Day of the week (1 = Sunday, 7 = Saturday)\n",
    "    weekofyear(\"full_date\").alias(\"week_of_year\"),  # Week of the year\n",
    "    month(\"full_date\").alias(\"month\"),  # Month (1-12)\n",
    "    date_format(\"full_date\", \"MMMM\").alias(\"month_name\"),  # Full name of the month\n",
    "    quarter(\"full_date\").alias(\"quarter\"),  # Quarter (1-4)\n",
    "    year(\"full_date\").alias(\"year\"),  # Year\n",
    "    when(dayofweek(\"full_date\").isin([1, 7]), 1).otherwise(0).alias(\"is_weekend\"),  # Weekend flag (1=weekend)\n",
    "    lit(0).alias(\"is_holiday\"),  # Dummy holiday flag (replace with actual holiday logic)\n",
    "    month(\"full_date\").alias(\"fiscal_month\"),  # Fiscal month (you can customize this logic)\n",
    "    quarter(\"full_date\").alias(\"fiscal_quarter\"),  # Fiscal quarter (you can customize this logic)\n",
    "    year(\"full_date\").alias(\"fiscal_year\")  # Fiscal year\n",
    ")\n",
    "\n",
    "dim_calendar.printSchema()\n",
    "# Show the resulting calendar dimension DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f63c99a-ce96-4dfe-a866-a9c25fdf2a34",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---+---------+-----------+------------+-----+----------+-------+----+----------+----------+------------+--------------+-----------+\n|date_key| full_date|day| day_name|day_of_week|week_of_year|month|month_name|quarter|year|is_weekend|is_holiday|fiscal_month|fiscal_quarter|fiscal_year|\n+--------+----------+---+---------+-----------+------------+-----+----------+-------+----+----------+----------+------------+--------------+-----------+\n|20150101|2015-01-01|  1| Thursday|          5|           1|    1|   January|      1|2015|         0|         0|           1|             1|       2015|\n|20150102|2015-01-02|  2|   Friday|          6|           1|    1|   January|      1|2015|         0|         0|           1|             1|       2015|\n|20150103|2015-01-03|  3| Saturday|          7|           1|    1|   January|      1|2015|         1|         0|           1|             1|       2015|\n|20150104|2015-01-04|  4|   Sunday|          1|           1|    1|   January|      1|2015|         1|         0|           1|             1|       2015|\n|20150105|2015-01-05|  5|   Monday|          2|           2|    1|   January|      1|2015|         0|         0|           1|             1|       2015|\n|20150106|2015-01-06|  6|  Tuesday|          3|           2|    1|   January|      1|2015|         0|         0|           1|             1|       2015|\n|20150107|2015-01-07|  7|Wednesday|          4|           2|    1|   January|      1|2015|         0|         0|           1|             1|       2015|\n|20150108|2015-01-08|  8| Thursday|          5|           2|    1|   January|      1|2015|         0|         0|           1|             1|       2015|\n+--------+----------+---+---------+-----------+------------+-----+----------+-------+----+----------+----------+------------+--------------+-----------+\nonly showing top 8 rows\n\n"
     ]
    }
   ],
   "source": [
    "dim_calendar.show(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7e1fd30-4c9d-47eb-8200-1a030684740f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+-----------------+-------------------+--------------------+--------------------+\n|payment_id|payment_method_id|payment_status_id|    processing_date|record_modified_date|         record_hash|\n+----------+-----------------+-----------------+-------------------+--------------------+--------------------+\n|         1|                1|                1|2024-10-15 00:13:13| 2024-10-14 15:44:24|6b86b273ff34fce19...|\n|         6|                6|                4|2024-10-15 00:13:13| 2024-10-14 15:44:24|e7f6c011776e8db7c...|\n|         3|                3|                1|2024-10-15 00:13:13| 2024-10-14 15:44:24|4e07408562bedb8b6...|\n|         5|                5|                2|2024-10-15 00:13:13| 2024-10-14 15:44:24|ef2d127de37b942ba...|\n|         4|                4|                4|2024-10-15 00:13:13| 2024-10-14 15:44:24|4b227777d4dd1fc61...|\n|         2|                2|                3|2024-10-15 00:13:13| 2024-10-14 15:44:24|d4735e3a265e16eee...|\n+----------+-----------------+-----------------+-------------------+--------------------+--------------------+\n\n+-----------------+-----------+-------------------+--------------------+--------------------+\n|payment_method_id|method_name|    processing_date|record_modified_date|         record_hash|\n+-----------------+-----------+-------------------+--------------------+--------------------+\n|                1|  Apple Pay|2024-10-15 00:13:16| 2024-10-14 15:42:53|6b86b273ff34fce19...|\n|                2|       Cash|2024-10-15 00:13:16| 2024-10-14 15:42:53|d4735e3a265e16eee...|\n|                3|Credit Card|2024-10-15 00:13:16| 2024-10-14 15:42:53|4e07408562bedb8b6...|\n|                4| Debit Card|2024-10-15 00:13:16| 2024-10-14 15:42:53|4b227777d4dd1fc61...|\n|                5| Google Pay|2024-10-15 00:13:16| 2024-10-14 15:42:53|ef2d127de37b942ba...|\n|                6|     PayPal|2024-10-15 00:13:16| 2024-10-14 15:42:53|e7f6c011776e8db7c...|\n+-----------------+-----------+-------------------+--------------------+--------------------+\n\n+-----------------+-----------+-------------------+--------------------+--------------------+\n|payment_status_id|status_name|    processing_date|record_modified_date|         record_hash|\n+-----------------+-----------+-------------------+--------------------+--------------------+\n|                1|  Completed|2024-10-15 00:13:18| 2024-10-14 15:42:36|6b86b273ff34fce19...|\n|                2|     Failed|2024-10-15 00:13:18| 2024-10-14 15:42:36|d4735e3a265e16eee...|\n|                3|    Pending|2024-10-15 00:13:18| 2024-10-14 15:42:36|4e07408562bedb8b6...|\n|                4|   Refunded|2024-10-15 00:13:18| 2024-10-14 15:42:36|4b227777d4dd1fc61...|\n+-----------------+-----------+-------------------+--------------------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "dataframes[\"payment\"].show(10)\n",
    "dataframes[\"paymentmethod\"].show()\n",
    "dataframes[\"paymentstatus\"].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb88d481-f67d-4e46-b470-4ad9cb878960",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+-----------+-----------------+-----------+\n|s_payment|payment_method_id|method_name|payment_status_id|status_name|\n+---------+-----------------+-----------+-----------------+-----------+\n|        0|                1|  Apple Pay|                1|  Completed|\n|        1|                1|  Apple Pay|                2|     Failed|\n|        2|                1|  Apple Pay|                3|    Pending|\n|        3|                1|  Apple Pay|                4|   Refunded|\n|        4|                2|       Cash|                1|  Completed|\n|        5|                2|       Cash|                2|     Failed|\n|        6|                2|       Cash|                3|    Pending|\n|        7|                2|       Cash|                4|   Refunded|\n|        8|                3|Credit Card|                1|  Completed|\n|        9|                3|Credit Card|                2|     Failed|\n|       10|                3|Credit Card|                3|    Pending|\n|       11|                3|Credit Card|                4|   Refunded|\n|       12|                4| Debit Card|                1|  Completed|\n|       13|                4| Debit Card|                2|     Failed|\n|       14|                4| Debit Card|                3|    Pending|\n|       15|                4| Debit Card|                4|   Refunded|\n|       16|                5| Google Pay|                1|  Completed|\n|       17|                5| Google Pay|                2|     Failed|\n|       18|                5| Google Pay|                3|    Pending|\n|       19|                5| Google Pay|                4|   Refunded|\n|       20|                6|     PayPal|                1|  Completed|\n|       21|                6|     PayPal|                2|     Failed|\n|       22|                6|     PayPal|                3|    Pending|\n|       23|                6|     PayPal|                4|   Refunded|\n+---------+-----------------+-----------+-----------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Perform a cross join to get all combinations of PaymentMethod and PaymentStatus\n",
    "combined_df = dataframes[\"paymentmethod\"].crossJoin(dataframes[\"paymentstatus\"])\n",
    "\n",
    "# Add an incremental surrogate key\n",
    "final_df = combined_df.withColumn(\"s_payment\", monotonically_increasing_id())\n",
    "\n",
    "# Select only the relevant columns (SurrogateKey, PaymentMethodID, PaymentStatusID)\n",
    "dim_payment = final_df.select(\"s_payment\", \"payment_method_id\", \"method_name\", \"payment_status_id\", \"status_name\")\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "dim_payment.show(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45dd1ac9-86fd-42d8-997b-e13ca5e928e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------------+-----------+-----------------+-----------+\n|s_payment|payment_method_id|method_name|payment_status_id|status_name|\n+---------+-----------------+-----------+-----------------+-----------+\n|        0|                1|  Apple Pay|                1|  Completed|\n|        1|                1|  Apple Pay|                2|     Failed|\n|        2|                1|  Apple Pay|                3|    Pending|\n|        3|                1|  Apple Pay|                4|   Refunded|\n|        4|                2|       Cash|                1|  Completed|\n|        5|                2|       Cash|                2|     Failed|\n|        6|                2|       Cash|                3|    Pending|\n|        7|                2|       Cash|                4|   Refunded|\n|        8|                3|Credit Card|                1|  Completed|\n|        9|                3|Credit Card|                2|     Failed|\n+---------+-----------------+-----------+-----------------+-----------+\nonly showing top 10 rows\n\n"
     ]
    }
   ],
   "source": [
    "dim_payment.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ffe9167-7280-437b-be58-ccb6fa9b5257",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------------+\n|location_id|   latitude|   longitude|\n+-----------+-----------+------------+\n|     534332|40.80208206|-73.94550323|\n|       8922|40.71480942|-74.01123047|\n|     245539|40.75943756|-73.98454285|\n|     272874|40.76562119|-73.98242950|\n|     173273|40.76070404|-73.98984528|\n|     320069|40.78929901|-73.97923279|\n|      74627|40.71456528|-73.99970245|\n|     422957|40.77065659|-73.96841431|\n|     442324|40.80597305|-73.96557617|\n|     360541|40.75173569|-73.97579193|\n|     354277|40.72886276|-73.97641754|\n|     198480|40.73231506|-73.98804474|\n|     420681|40.79624939|-73.96874237|\n|     427568|40.75556946|-73.96782684|\n|     118623|40.71798325|-73.99394989|\n|     173854|40.76736832|-73.98980713|\n|     539166|40.75203323|-73.93933868|\n|     421466|40.76403046|-73.96862030|\n|     361052|40.76347351|-73.97573853|\n|     527211|40.77400589|-73.94878387|\n+-----------+-----------+------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "dim_location = dataframes[\"location\"].select(\"location_id\", \"latitude\", \"longitude\")\n",
    "dim_location.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92383ad4-47e6-4111-9705-650fcf61f109",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+------------------+-------------------+-------------------+-------------------+-------------------+--------------------+--------------------+\n|request_id|passenger_id|pickup_location_id|dropoff_location_id|       request_time|        accept_time|    processing_date|record_modified_date|         record_hash|\n+----------+------------+------------------+-------------------+-------------------+-------------------+-------------------+--------------------+--------------------+\n|    237680|      116990|            325968|             282621|2015-01-13 21:04:00|2015-01-13 21:13:00|2024-10-15 00:13:20| 2024-10-14 15:47:33|39c6325cdb5e629fa...|\n|    273431|      136300|             68934|             233428|2015-01-08 01:34:00|2015-01-08 01:41:00|2024-10-15 00:13:20| 2024-10-14 15:47:33|28c653b4e7e206ae4...|\n|     34051|       16972|            375948|              98347|2015-01-26 13:56:00|2015-01-26 13:59:00|2024-10-15 00:13:20| 2024-10-14 15:47:33|71c70b5555bbb8ac4...|\n|    370418|      184327|            401457|             294000|2015-01-28 05:51:00|2015-01-28 05:56:00|2024-10-15 00:13:20| 2024-10-14 15:47:33|9c38faef39df39581...|\n|    502739|      252115|            329893|             475830|2015-01-16 07:09:00|2015-01-16 07:11:00|2024-10-15 00:13:20| 2024-10-14 15:47:33|e15b11c256645853f...|\n+----------+------------+------------------+-------------------+-------------------+-------------------+-------------------+--------------------+--------------------+\nonly showing top 5 rows\n\n+-------+----------+---------+----------+----------+-------------------+-------------------+-------------+---------+----------+-------+----------+------------+---------------------+-------------------+--------------------+--------------------+\n|trip_id|request_id|driver_id|vehicle_id|payment_id|    trip_start_time|      trip_end_time|trip_distance|base_fare|extra_fare|mta_tax|tip_amount|tolls_amount|improvement_surcharge|    processing_date|record_modified_date|         record_hash|\n+-------+----------+---------+----------+----------+-------------------+-------------------+-------------+---------+----------+-------+----------+------------+---------------------+-------------------+--------------------+--------------------+\n|     27|    277968|   849799|     30165|         5|2015-01-15 19:05:00|2015-01-15 19:16:00|         1.53|     9.00|      1.00|   0.50|      0.00|        0.00|                 0.30|2024-10-15 00:13:26| 2024-10-14 15:49:31|7f07810e08175b5ba...|\n|    708|     35728|   751820|    266933|         1|2015-01-10 20:14:00|2015-01-10 20:14:00|         0.00|     2.50|      0.50|   0.50|      0.00|        0.00|                 0.30|2024-10-15 00:13:26| 2024-10-14 15:49:31|fcd795c49d44a16a5...|\n|    987|    141396|   876384|    243613|         4|2015-01-07 20:40:00|2015-01-07 20:47:00|         1.30|     7.00|      0.50|   0.50|      1.65|        0.00|                 0.30|2024-10-15 00:13:26| 2024-10-14 15:49:31|609e082897dc94d14...|\n|   1885|    147091|   877543|    188065|         5|2015-01-21 06:31:00|2015-01-21 06:39:00|         0.90|     7.00|      0.00|   0.50|      0.00|        0.00|                 0.30|2024-10-15 00:13:26| 2024-10-14 15:49:31|fbd32311c77c8d04c...|\n|   1963|    386848|   766687|    330093|         2|2015-01-07 22:02:00|2015-01-07 22:16:00|         4.00|    15.00|      0.50|   0.50|      3.25|        0.00|                 0.30|2024-10-15 00:13:26| 2024-10-14 15:49:31|c214abbd4034f69e2...|\n+-------+----------+---------+----------+----------+-------------------+-------------------+-------------+---------+----------+-------+----------+------------+---------------------+-------------------+--------------------+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "dataframes[\"request\"].show(5)\n",
    "dataframes[\"trip\"].show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a13f18f-49cd-4985-a1c4-7f225b58c4b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+------------------+-------------------+---------------+--------------+------------------+----------------+---------+-------------+---------+----------+-------+----------+------------+---------------------+\n|driver_id|passenger_id|pickup_location_id|dropoff_location_id|request_datekey|accept_datekey|trip_start_datekey|trip_end_datekey|s_payment|trip_distance|base_fare|extra_fare|mta_tax|tip_amount|tolls_amount|improvement_surcharge|\n+---------+------------+------------------+-------------------+---------------+--------------+------------------+----------------+---------+-------------+---------+----------+-------+----------+------------+---------------------+\n|   786475|       17820|            440218|             406815|       20150103|      20150103|          20150103|        20150103|       17|         0.50|     4.50|      0.00|   0.50|      0.00|        0.00|                 0.00|\n|   927190|       17899|            351563|             555384|       20150130|      20150130|          20150130|        20150130|       15|         9.52|    29.50|      0.00|   0.50|      6.97|        5.33|                 0.30|\n|   756354|       18769|            540389|             538515|       20150122|      20150122|          20150122|        20150122|       17|         1.50|     7.00|      0.00|   0.50|      2.00|        0.00|                 0.30|\n|   810698|       29008|            187165|             235622|       20150125|      20150125|          20150125|        20150125|       17|         2.62|    13.00|      0.00|   0.50|      0.00|        0.00|                 0.30|\n|   758036|       53333|            308519|             411373|       20150107|      20150107|          20150107|        20150107|       17|         1.50|     9.00|      1.00|   0.50|      0.00|        0.00|                 0.30|\n|   772997|       74465|            466407|             479678|       20150101|      20150101|          20150101|        20150101|        6|         1.90|     9.20|      0.00|   0.50|      2.00|        0.00|                 0.00|\n|   830855|       76725|            302575|             247019|       20150116|      20150116|          20150116|        20150116|        6|         0.20|     3.50|      1.00|   0.50|      0.00|        0.00|                 0.30|\n|   762137|       85264|            116820|              59761|       20150126|      20150126|          20150126|        20150126|       23|         1.31|     8.50|      0.00|   0.50|      2.00|        0.00|                 0.30|\n|   961639|      131017|             30330|             348103|       20150126|      20150126|          20150126|        20150126|       23|         3.00|    18.00|      0.00|   0.50|      4.70|        0.00|                 0.30|\n|   785585|      131599|            304267|             556212|       20150108|      20150108|          20150108|        20150108|       23|         9.92|    34.00|      0.00|   0.50|      6.80|        0.00|                 0.30|\n|   831310|      136300|             68934|             233428|       20150108|      20150108|          20150108|        20150108|        0|         3.23|    12.50|      0.50|   0.50|      2.60|        0.00|                 0.30|\n|   864499|      139092|            243744|             172120|       20150105|      20150105|          20150105|        20150105|        0|         2.10|     8.50|      0.50|   0.50|      1.00|        0.00|                 0.30|\n|   899898|      145423|            421653|             364747|       20150109|      20150109|          20150109|        20150109|       23|         1.48|     8.50|      1.00|   0.50|      1.90|        0.00|                 0.30|\n|   827790|      166276|            234159|             406223|       20150127|      20150127|          20150127|        20150127|       17|         1.09|     5.00|      0.00|   0.50|      0.00|        0.00|                 0.30|\n|   848743|      202216|            439427|             426411|       20150102|      20150102|          20150102|        20150102|       17|         1.09|     6.00|      0.50|   0.50|      1.62|        0.00|                 0.30|\n|   884045|      214835|            451307|             386519|       20150118|      20150118|          20150118|        20150118|        0|         1.14|     5.50|      0.00|   0.50|      0.00|        0.00|                 0.30|\n|   914210|      262235|            237698|             312740|       20150114|      20150114|          20150114|        20150114|       23|         1.71|     9.50|      0.00|   0.50|      1.50|        0.00|                 0.30|\n|   981409|      282068|            236459|             366975|       20150125|      20150125|          20150125|        20150125|       23|         1.50|     7.00|      0.50|   0.50|      2.00|        0.00|                 0.30|\n|   918510|       21993|            562731|             567647|       20150120|      20150120|          20150120|        20150120|       15|         3.20|    15.50|      1.00|   0.50|      0.00|        0.00|                 0.30|\n|   723393|       26314|            383924|             358230|       20150110|      20150110|          20150110|        20150110|        8|         1.80|    15.00|      0.00|   0.50|      0.00|        0.00|                 0.30|\n|   748038|       41849|            137912|             525749|       20150124|      20150124|          20150124|        20150124|        6|         3.90|    16.00|      0.50|   0.50|      0.00|        0.00|                 0.30|\n|   804171|       48428|            174491|             195208|       20150108|      20150108|          20150108|        20150108|       15|         2.40|    14.00|      0.50|   0.50|      0.00|        0.00|                 0.30|\n|   878006|       54655|            383908|             284067|       20150107|      20150107|          20150107|        20150107|       17|         1.57|     7.00|      0.50|   0.50|      1.88|        0.00|                 0.30|\n|   867757|       57112|            299485|             128850|       20150131|      20150131|          20150131|        20150131|        8|         0.90|     6.00|      0.00|   0.50|      1.50|        0.00|                 0.30|\n+---------+------------+------------------+-------------------+---------------+--------------+------------------+----------------+---------+-------------+---------+----------+-------+----------+------------+---------------------+\nonly showing top 24 rows\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Join the DataFrames\n",
    "fact_request = dataframes[\"request\"].join(dataframes[\"trip\"], dataframes[\"request\"][\"request_id\"] == dataframes[\"trip\"][\"request_id\"], \"left\") \\\n",
    "    .join(dataframes[\"payment\"], dataframes[\"trip\"][\"payment_id\"] == dataframes[\"payment\"][\"payment_id\"], \"left\") \\\n",
    "    .join(dim_payment, \n",
    "          (dataframes[\"payment\"][\"payment_method_id\"] == dim_payment[\"payment_method_id\"]) & \n",
    "          (dataframes[\"payment\"][\"payment_status_id\"] == dim_payment[\"payment_status_id\"]), \n",
    "          \"left\") \\\n",
    "    .select(\n",
    "        dataframes[\"trip\"][\"driver_id\"],\n",
    "        dataframes[\"request\"][\"passenger_id\"],\n",
    "        dataframes[\"request\"][\"pickup_location_id\"],\n",
    "        dataframes[\"request\"][\"dropoff_location_id\"],\n",
    "        date_format(dataframes[\"request\"][\"request_time\"], 'yyyyMMdd').alias(\"request_datekey\"),  # Renamed and formatted\n",
    "        date_format(dataframes[\"request\"][\"accept_time\"], 'yyyyMMdd').alias(\"accept_datekey\"),    # Renamed and formatted\n",
    "        date_format(dataframes[\"trip\"][\"trip_start_time\"], 'yyyyMMdd').alias(\"trip_start_datekey\"),   # Renamed\n",
    "        date_format(dataframes[\"trip\"][\"trip_end_time\"], 'yyyyMMdd').alias(\"trip_end_datekey\"),       # Renamed\n",
    "        dim_payment[\"s_payment\"],\n",
    "        dataframes[\"trip\"][\"trip_distance\"],\n",
    "        dataframes[\"trip\"][\"base_fare\"],\n",
    "        dataframes[\"trip\"][\"extra_fare\"],\n",
    "        dataframes[\"trip\"][\"mta_tax\"],\n",
    "        dataframes[\"trip\"][\"tip_amount\"],\n",
    "        dataframes[\"trip\"][\"tolls_amount\"],\n",
    "        dataframes[\"trip\"][\"improvement_surcharge\"]\n",
    "    )\n",
    "\n",
    "fact_request.show(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68ef1faf-42a0-4fe5-8368-6939c7a7e29e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dataframes = [dim_calendar, dim_location, dim_payment, dim_user, fact_request]\n",
    "# Names of the original DataFrames\n",
    "dataframe_names = [\"dim_calendar\", \"dim_location\", \"dim_payment\", \"dim_user\", \"fct_request\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01b2bfee-ffff-41ab-ae7f-55e75d36a6eb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "processing_date = date_trunc('second', current_timestamp())\n",
    "\n",
    "for i, df in enumerate(dataframes):\n",
    "    # Apply column name conversion\n",
    "    df = df.withColumn(\"processing_date\", processing_date)\n",
    "\n",
    "    # Reassign the modified DataFrame back to the original global variable\n",
    "    globals()[dataframe_names[i]] = df\n",
    "    \n",
    "    # Show the first 5 rows of the updated DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1154a44-29f6-4b79-94e1-89c047834cc8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of DataFrames, locations, and hash columns with an attribute for slowly changing dimension (SCD)\n",
    "tables_info = [\n",
    "    {\"df\": dim_user, \"location\": \"/mnt/gold/dim_user\", \"hash_columns\": [\"user_id\", \"full_name\"], \"is_scd\": True},\n",
    "    {\"df\": dim_calendar, \"location\": \"/mnt/gold//dim_calendar\", \"hash_columns\": [\"date_key\"], \"is_scd\": True},\n",
    "    {\"df\": dim_location, \"location\": \"/mnt/gold/dim_location\", \"hash_columns\": [\"location_id\"], \"is_scd\": True},\n",
    "    {\"df\": dim_payment, \"location\": \"/mnt/gold/dim_payment\", \"hash_columns\": [\"s_payment\"], \"is_scd\": True},\n",
    "    {\"df\": fact_request, \"location\": \"/mnt/gold/fct_request\", \"hash_columns\": [\"driver_id\", \"trip_start_datekey\"], \"is_scd\": True}\n",
    "]\n",
    "\n",
    "def deduplicate_source_df(source_df: DataFrame, hash_columns: list) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Deduplicates the source DataFrame based on the hash columns.\n",
    "    \n",
    "    Args:\n",
    "        source_df (DataFrame): The source DataFrame to be deduplicated.\n",
    "        hash_columns (list): List of columns to be used for deduplication.\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: The deduplicated DataFrame.\n",
    "    \"\"\"\n",
    "    return source_df.dropDuplicates(hash_columns)\n",
    "\n",
    "# Function to generate a hash column for specified columns in a DataFrame\n",
    "def generate_hash_column(df: DataFrame, columns: list, hash_column_name: str = \"record_hash\") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a hash column for specified columns in the DataFrame using SHA-256.\n",
    "    \"\"\"\n",
    "    return df.withColumn(hash_column_name, sha2(concat_ws(\"||\", *columns), 256))\n",
    "\n",
    "# Function to build merge condition using hash\n",
    "def build_merge_condition_with_hash(target_alias: str, source_alias: str, hash_column: str) -> str:\n",
    "    \"\"\"\n",
    "    Builds a merge condition string using the hash column.\n",
    "    \"\"\"\n",
    "    return f\"{target_alias}.{hash_column} = {source_alias}.{hash_column}\"\n",
    "\n",
    "# Function to merge Delta tables based on SCD flag\n",
    "def merge_delta_table(source_df: DataFrame, delta_location: str, hash_columns: list, is_scd: bool):\n",
    "    \"\"\"\n",
    "    Performs merge for slowly changing dimension (SCD) tables. If is_scd is False, data is simply overwritten.\n",
    "    \"\"\"\n",
    "    # Generate hash column for the source DataFrame\n",
    "    source_df_hashed = generate_hash_column(source_df, hash_columns)\n",
    "    \n",
    "    # If the table is an SCD, perform a merge operation\n",
    "    if is_scd:\n",
    "        try:\n",
    "            # Check if the Delta table exists at the specified location\n",
    "            if DeltaTable.isDeltaTable(spark, delta_location):\n",
    "                print(f\"Delta table found at {delta_location}. Proceeding with merge...\")\n",
    "                delta_table = DeltaTable.forPath(spark, delta_location)\n",
    "                \n",
    "                # Alias for target and source\n",
    "                target_alias = \"target\"\n",
    "                source_alias = \"src\"\n",
    "                \n",
    "                # Generate hash column for the target Delta table\n",
    "                delta_table_df = spark.read.format(\"delta\").load(delta_location)\n",
    "                delta_table_hashed = generate_hash_column(delta_table_df, hash_columns)\n",
    "                \n",
    "                # Build the merge condition using the hash column\n",
    "                merge_condition = build_merge_condition_with_hash(target_alias, source_alias, \"record_hash\")\n",
    "                \n",
    "                # Perform the merge operation\n",
    "                delta_table.alias(target_alias).merge(\n",
    "                    source=source_df_hashed.alias(source_alias),\n",
    "                    condition=merge_condition\n",
    "                ).whenMatchedUpdateAll().whenNotMatchedInsertAll().execute()\n",
    "                \n",
    "                print(f\"Merge completed for {delta_location}.\")\n",
    "            else:\n",
    "                # If Delta table doesn't exist, write the DataFrame to that location\n",
    "                print(f\"No Delta table found at {delta_location}. Writing new DataFrame...\")\n",
    "                source_df_hashed.write.mode(\"overwrite\").format(\"delta\").save(delta_location)\n",
    "                print(f\"DataFrame written to {delta_location}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing table at {delta_location}: {e}\")\n",
    "    else:\n",
    "        # For non-SCD tables, just overwrite the data\n",
    "        print(f\"{delta_location} is not an SCD table. Overwriting...\")\n",
    "        source_df_hashed.write.mode(\"overwrite\").format(\"delta\").save(delta_location)\n",
    "        print(f\"DataFrame overwritten at {delta_location}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28076b70-026b-4bb7-8c2b-2f63aeb3c19e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema of source DataFrame:\nroot\n |-- user_id: integer (nullable = true)\n |-- full_name: string (nullable = true)\n |-- email: string (nullable = true)\n |-- phone_number: string (nullable = true)\n |-- vehicle_id: string (nullable = false)\n |-- vehicle_make: string (nullable = false)\n |-- vehicle_model: string (nullable = false)\n |-- vehicle_year: string (nullable = false)\n |-- vehicle_color: string (nullable = false)\n |-- vehicle_license_plate: string (nullable = false)\n |-- processing_date: timestamp (nullable = true)\n\nDelta table found at /mnt/gold/dim_user. Proceeding with merge...\nMerge completed for /mnt/gold/dim_user.\nSchema of source DataFrame:\nroot\n |-- date_key: string (nullable = false)\n |-- full_date: date (nullable = false)\n |-- day: integer (nullable = false)\n |-- day_name: string (nullable = false)\n |-- day_of_week: integer (nullable = false)\n |-- week_of_year: integer (nullable = false)\n |-- month: integer (nullable = false)\n |-- month_name: string (nullable = false)\n |-- quarter: integer (nullable = false)\n |-- year: integer (nullable = false)\n |-- is_weekend: integer (nullable = false)\n |-- is_holiday: integer (nullable = false)\n |-- fiscal_month: integer (nullable = false)\n |-- fiscal_quarter: integer (nullable = false)\n |-- fiscal_year: integer (nullable = false)\n |-- processing_date: timestamp (nullable = true)\n\n/mnt/gold//dim_calendar is not an SCD table. Overwriting...\nDataFrame overwritten at /mnt/gold//dim_calendar.\nSchema of source DataFrame:\nroot\n |-- location_id: integer (nullable = true)\n |-- latitude: decimal(12,8) (nullable = true)\n |-- longitude: decimal(12,8) (nullable = true)\n |-- processing_date: timestamp (nullable = true)\n\n/mnt/gold/dim_location is not an SCD table. Overwriting...\nDataFrame overwritten at /mnt/gold/dim_location.\nSchema of source DataFrame:\nroot\n |-- s_payment: long (nullable = false)\n |-- payment_method_id: integer (nullable = true)\n |-- method_name: string (nullable = true)\n |-- payment_status_id: integer (nullable = true)\n |-- status_name: string (nullable = true)\n |-- processing_date: timestamp (nullable = true)\n\n/mnt/gold/dim_payment is not an SCD table. Overwriting...\nDataFrame overwritten at /mnt/gold/dim_payment.\nSchema of source DataFrame:\nroot\n |-- driver_id: integer (nullable = true)\n |-- passenger_id: integer (nullable = true)\n |-- pickup_location_id: integer (nullable = true)\n |-- dropoff_location_id: integer (nullable = true)\n |-- request_datekey: string (nullable = true)\n |-- accept_datekey: string (nullable = true)\n |-- trip_start_datekey: string (nullable = true)\n |-- trip_end_datekey: string (nullable = true)\n |-- s_payment: long (nullable = true)\n |-- trip_distance: decimal(10,2) (nullable = true)\n |-- base_fare: decimal(10,2) (nullable = true)\n |-- extra_fare: decimal(10,2) (nullable = true)\n |-- mta_tax: decimal(10,2) (nullable = true)\n |-- tip_amount: decimal(10,2) (nullable = true)\n |-- tolls_amount: decimal(10,2) (nullable = true)\n |-- improvement_surcharge: decimal(10,2) (nullable = true)\n\n/mnt/gold/fct_request is not an SCD table. Overwriting...\nDataFrame overwritten at /mnt/gold/fct_request.\n"
     ]
    }
   ],
   "source": [
    "# Loop through each table and perform the operations\n",
    "for table_info in tables_info:\n",
    "    # Print the schema of the source DataFrame\n",
    "    print(\"Schema of source DataFrame:\")\n",
    "    table_info[\"df\"].printSchema()  # Ensure we are printing the schema of the specific DataFrame\n",
    "\n",
    "    # Deduplicate the source DataFrame based on hash columns\n",
    "    df = deduplicate_source_df(table_info[\"df\"], table_info[\"hash_columns\"])\n",
    "    \n",
    "    # Prepare the Delta table location and SCD flag\n",
    "    delta_location = table_info[\"location\"]\n",
    "    hash_columns = table_info[\"hash_columns\"]\n",
    "    is_scd = table_info[\"is_scd\"]  # Check if it's a slowly changing dimension\n",
    "\n",
    "    # Perform merge or overwrite based on is_scd flag\n",
    "    merge_delta_table(df, delta_location, hash_columns, is_scd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67edca97-525d-4415-92cb-567218d52a67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+--------------------+--------------+----------+-------------+-------------+------------+-------------+---------------------+-------------------+--------------------+\n|user_id|      full_name|               email|  phone_number|vehicle_id| vehicle_make|vehicle_model|vehicle_year|vehicle_color|vehicle_license_plate|    processing_date|         record_hash|\n+-------+---------------+--------------------+--------------+----------+-------------+-------------+------------+-------------+---------------------+-------------------+--------------------+\n| 700001|   Aaron Abbott|angela67@example.com|(453) 832-3608|    168434|      Hyundai|     Santa Fe|        2006|       Silver|              3BW 116|2024-10-15 00:15:01|6e1ef69ae8734c534...|\n|      1|   Aaron Acosta| vbishop@example.net|(677) 367-9557| Passenger|    Passenger|    Passenger|   Passenger|    Passenger|            Passenger|2024-10-15 00:15:01|21d31195f82942e05...|\n| 700002|   Aaron Acosta|vanessa20@example...|(953) 599-6007|     11618|          BMW|     5 Series|        2017|       Orange|                 389J|2024-10-15 00:15:01|62d5bc8c4ecbeaf3d...|\n|      2|    Aaron Adams| james82@example.com|(332) 224-7965| Passenger|    Passenger|    Passenger|   Passenger|    Passenger|            Passenger|2024-10-15 00:15:01|683e6c22fa1e45bef...|\n| 700006|    Aaron Adams| emily69@example.net|(217) 156-8782|     67661|    Chevrolet|        Tahoe|        1994|         Blue|              YCF 385|2024-10-15 00:15:01|4866e617e54ca7de7...|\n| 700005|    Aaron Adams|  dbowen@example.net|(672) 995-6696|     23039|          BMW|           X5|        1996|         Blue|              IIV-491|2024-10-15 00:15:01|95bcf56ae7d7d1a85...|\n| 700003|    Aaron Adams|angela64@example.com|(619) 154-2732|    359266|   Volkswagen|       Passat|        1997|        Green|              SRO 232|2024-10-15 00:15:01|c5cb6cb18f3c64b7d...|\n| 700007|    Aaron Adams|jesseschwartz@exa...|(250) 242-4652|     91967|         Ford|        F-150|        2017|         Gray|             50-41182|2024-10-15 00:15:01|09f0d6b77ee353721...|\n|      3|    Aaron Adams|nicholas92@exampl...|(351) 943-8670| Passenger|    Passenger|    Passenger|   Passenger|    Passenger|            Passenger|2024-10-15 00:15:01|500bf842d2becc183...|\n| 700008|    Aaron Adams|  jill51@example.org|(120) 200-5627|    138962|        Honda|          Fit|        2006|       Silver|              65M 278|2024-10-15 00:15:01|2136a8fcbeb5a2344...|\n|      4|    Aaron Adams|zjohnson@example.com|(324) 384-5822| Passenger|    Passenger|    Passenger|   Passenger|    Passenger|            Passenger|2024-10-15 00:15:01|60f62b9afaac9bbb8...|\n| 700004|    Aaron Adams|beckdaniel@exampl...|(987) 878-1073|     52562|    Chevrolet|       Malibu|        2022|        Black|              324 JEN|2024-10-15 00:15:01|d419e2eef5018e4d7...|\n| 700009|   Aaron Adkins|   jchan@example.com|(959) 936-7702|    194019|          Kia|       Optima|        2005|         Blue|              VJP4675|2024-10-15 00:15:01|64243d430f017b27b...|\n| 700011|  Aaron Aguilar|reyeselizabeth@ex...|(554) 632-2702|    229699|Mercedes-Benz|      E-Class|        1994|        Black|              6-13526|2024-10-15 00:15:01|6b3dc250c9028f67b...|\n| 700010|  Aaron Aguilar|beverlyhale@examp...|(862) 346-3495|    102860|         Ford|       Fusion|        2012|        White|             86-85485|2024-10-15 00:15:01|9da28f3e6bf59f72f...|\n|      5|  Aaron Aguilar|anthony78@example...|(867) 762-3031| Passenger|    Passenger|    Passenger|   Passenger|    Passenger|            Passenger|2024-10-15 00:15:01|a966dd203faf1291c...|\n|      6|  Aaron Aguilar|wilsonruben@examp...|(376) 707-8408| Passenger|    Passenger|    Passenger|   Passenger|    Passenger|            Passenger|2024-10-15 00:15:01|7d403c55cd6dae43e...|\n|      7|  Aaron Aguirre|samantha45@exampl...|(147) 383-2497| Passenger|    Passenger|    Passenger|   Passenger|    Passenger|            Passenger|2024-10-15 00:15:01|e67e82d0ddd8f2482...|\n| 700012|Aaron Alexander|jasonhanna@exampl...|(868) 281-9704|    191874|          Kia|        Forte|        2011|        White|             0Z W8141|2024-10-15 00:15:01|02ad6af82b5132694...|\n| 700015|Aaron Alexander|sotojohn@example.com|(925) 698-5822|    363420|   Volkswagen|       Passat|        2017|       Yellow|                71475|2024-10-15 00:15:01|ac160162601bb177f...|\n+-------+---------------+--------------------+--------------+----------+-------------+-------------+------------+-------------+---------------------+-------------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"delta\").load(\"/mnt/gold/dim_user\").orderBy(\"full_name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3198ec0-96ab-41ee-81f0-790fe4bb988e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dim_calendar\nCreating external table: gold.dim_calendar\nDelta table path: /mnt/gold/dim_calendar\ndim_location\nCreating external table: gold.dim_location\nDelta table path: /mnt/gold/dim_location\ndim_payment\nCreating external table: gold.dim_payment\nDelta table path: /mnt/gold/dim_payment\ndim_user\nCreating external table: gold.dim_user\nDelta table path: /mnt/gold/dim_user\nfct_request\nCreating external table: gold.fct_request\nDelta table path: /mnt/gold/fct_request\n+--------+------------+-----------+\n|database|   tableName|isTemporary|\n+--------+------------+-----------+\n|    gold|dim_calendar|      false|\n|    gold|dim_location|      false|\n|    gold| dim_payment|      false|\n|    gold|    dim_user|      false|\n|    gold| fct_request|      false|\n+--------+------------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "# Create the gold schema once outside the loop\n",
    "spark.sql(\"CREATE SCHEMA IF NOT EXISTS gold\")\n",
    "\n",
    "for file in dataframe_names:\n",
    "    print(file)\n",
    "    table_name = f\"gold.{file}\"\n",
    "    print(f\"Creating external table: {table_name}\")\n",
    "    \n",
    "    # Set the current database to 'gold'\n",
    "    spark.sql(\"USE gold\")\n",
    "    \n",
    "    delta_table_path = f\"/mnt/gold/{file}\"\n",
    "    print(f\"Delta table path: {delta_table_path}\")\n",
    "    #spark.sql(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "    spark.sql(f\"\"\"\n",
    "        CREATE EXTERNAL TABLE IF NOT EXISTS {table_name}\n",
    "        USING DELTA \n",
    "        LOCATION '{delta_table_path}'\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "\n",
    "# Optionally, show the tables after the loop to inspect\n",
    "spark.sql(\"SHOW TABLES IN gold\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0b99fb7-3433-4ea4-a777-944af92248e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold.dim_calendar\ndim_calendar\ngold.dim_location\ndim_location\ngold.dim_payment\ndim_payment\ngold.dim_user\ndim_user\ngold.fct_request\nfct_request\n"
     ]
    }
   ],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Dictionary to store the DeltaTable objects\n",
    "delta_tables = {}\n",
    "\n",
    "for table in dataframe_names:\n",
    "    # Define the table location\n",
    "    table_name = f\"gold.{table}\"\n",
    "    print(table_name)\n",
    "    print(table)\n",
    "    # Store the DeltaTable object in the dictionary using the file name as the key\n",
    "    delta_tables[table] = DeltaTable.forName(spark, table_name)  # Load table from path\n",
    "\n",
    "    # Check if the table has been vacuumed in the last 30 days\n",
    "    if delta_tables[table].history(30).filter(\"operation = 'VACUUM START'\").count() == 0:\n",
    "        # Optimize the table for better query performance\n",
    "        delta_tables[table].optimize()\n",
    "        # Perform vacuum operation (default is to keep data for 7 days)\n",
    "        delta_tables[table].vacuum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5df4f9f9-658f-42c2-9e42-7a15b75e1cc1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "292201"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format(\"delta\").load(f\"/mnt/gold/fct_request\").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "558f032e-74f1-4d70-b634-21e7f1942e7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-3799327554425638>, line 12\u001B[0m\n",
       "\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(table)\n",
       "\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Store the DeltaTable object in the dictionary using the file name as the key\u001B[39;00m\n",
       "\u001B[0;32m---> 12\u001B[0m delta_tables[table] \u001B[38;5;241m=\u001B[39m DeltaTable\u001B[38;5;241m.\u001B[39mforPath(spark, table_name)  \u001B[38;5;66;03m# Load table from path\u001B[39;00m\n",
       "\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Check if the table has been vacuumed in the last 30 days\u001B[39;00m\n",
       "\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m delta_tables[table]\u001B[38;5;241m.\u001B[39mhistory(\u001B[38;5;241m30\u001B[39m)\u001B[38;5;241m.\u001B[39mfilter(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moperation = \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVACUUM START\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mcount() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
       "\u001B[1;32m     16\u001B[0m     \u001B[38;5;66;03m# Optimize the table for better query performance\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/delta/tables.py:402\u001B[0m, in \u001B[0;36mDeltaTable.forPath\u001B[0;34m(cls, sparkSession, path, hadoopConf)\u001B[0m\n",
       "\u001B[1;32m    399\u001B[0m jvm: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJVMView\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m=\u001B[39m sparkSession\u001B[38;5;241m.\u001B[39m_sc\u001B[38;5;241m.\u001B[39m_jvm  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n",
       "\u001B[1;32m    400\u001B[0m jsparkSession: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJavaObject\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m=\u001B[39m sparkSession\u001B[38;5;241m.\u001B[39m_jsparkSession  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n",
       "\u001B[0;32m--> 402\u001B[0m jdt \u001B[38;5;241m=\u001B[39m \u001B[43mjvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdelta\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtables\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDeltaTable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjsparkSession\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhadoopConf\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    403\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DeltaTable(sparkSession, jdt)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1356\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n",
       "\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n",
       "\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n",
       "\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
       "\n",
       "\u001B[0;31mAnalysisException\u001B[0m: [DELTA_MISSING_DELTA_TABLE] `gold.dim_calendar` is not a Delta table."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AnalysisException",
        "evalue": "[DELTA_MISSING_DELTA_TABLE] `gold.dim_calendar` is not a Delta table."
       },
       "metadata": {
        "errorSummary": "Command skipped"
       },
       "removedWidgets": [],
       "sqlProps": {
        "errorClass": "DELTA_MISSING_DELTA_TABLE",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "sqlState": "42P01",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAnalysisException\u001B[0m                         Traceback (most recent call last)",
        "File \u001B[0;32m<command-3799327554425638>, line 12\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28mprint\u001B[39m(table)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Store the DeltaTable object in the dictionary using the file name as the key\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m delta_tables[table] \u001B[38;5;241m=\u001B[39m DeltaTable\u001B[38;5;241m.\u001B[39mforPath(spark, table_name)  \u001B[38;5;66;03m# Load table from path\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Check if the table has been vacuumed in the last 30 days\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m delta_tables[table]\u001B[38;5;241m.\u001B[39mhistory(\u001B[38;5;241m30\u001B[39m)\u001B[38;5;241m.\u001B[39mfilter(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moperation = \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVACUUM START\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mcount() \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;66;03m# Optimize the table for better query performance\u001B[39;00m\n",
        "File \u001B[0;32m/databricks/spark/python/delta/tables.py:402\u001B[0m, in \u001B[0;36mDeltaTable.forPath\u001B[0;34m(cls, sparkSession, path, hadoopConf)\u001B[0m\n\u001B[1;32m    399\u001B[0m jvm: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJVMView\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m=\u001B[39m sparkSession\u001B[38;5;241m.\u001B[39m_sc\u001B[38;5;241m.\u001B[39m_jvm  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m    400\u001B[0m jsparkSession: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJavaObject\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m=\u001B[39m sparkSession\u001B[38;5;241m.\u001B[39m_jsparkSession  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m--> 402\u001B[0m jdt \u001B[38;5;241m=\u001B[39m \u001B[43mjvm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdelta\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtables\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDeltaTable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjsparkSession\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhadoopConf\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    403\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DeltaTable(sparkSession, jdt)\n",
        "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1355\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1349\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1350\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1351\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1352\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1354\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1355\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1356\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1358\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1359\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(temp_arg, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_detach\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
        "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions/captured.py:230\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    226\u001B[0m converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\u001B[1;32m    227\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(converted, UnknownException):\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;66;03m# JVM exception message.\u001B[39;00m\n\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m converted \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
        "\u001B[0;31mAnalysisException\u001B[0m: [DELTA_MISSING_DELTA_TABLE] `gold.dim_calendar` is not a Delta table."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Join the DataFrames with aliases for clarity\n",
    "\"\"\"\n",
    "fact_request_with_user_payment = fact_request.alias(\"fr\") \\\n",
    "    .join(dim_user.alias(\"du\"), col(\"fr.driver_id\") == col(\"du.user_id\"), \"left\") \\\n",
    "    .join(dim_user.alias(\"pu\"), col(\"fr.passenger_id\") == col(\"pu.user_id\"), \"left\") \\\n",
    "    .join(dim_payment.alias(\"dp\"), col(\"fr.s_payment\") == col(\"dp.s_payment\"), \"left\") \\\n",
    "    .select(\n",
    "        col(\"fr.driver_id\"),\n",
    "        col(\"fr.passenger_id\"),\n",
    "        col(\"fr.pickup_location_id\"),\n",
    "        col(\"fr.dropoff_location_id\"),\n",
    "        col(\"fr.request_datekey\"),\n",
    "        col(\"fr.accept_datekey\"),\n",
    "        col(\"fr.trip_start_datekey\"),\n",
    "        col(\"fr.trip_end_datekey\"),\n",
    "        col(\"fr.s_payment\"),\n",
    "        col(\"fr.trip_distance\"),\n",
    "        col(\"fr.base_fare\"),\n",
    "        col(\"fr.extra_fare\"),\n",
    "        col(\"fr.mta_tax\"),\n",
    "        col(\"fr.tip_amount\"),\n",
    "        col(\"fr.tolls_amount\"),\n",
    "        col(\"fr.improvement_surcharge\"),\n",
    "        col(\"du.full_name\").alias(\"driver_name\"),\n",
    "        col(\"du.email\").alias(\"driver_email\"),\n",
    "        col(\"du.phone_number\").alias(\"driver_phone\"),\n",
    "        col(\"du.vehicle_id\").alias(\"driver_vehicle_id\"),\n",
    "        col(\"du.vehicle_make\").alias(\"driver_vehicle_make\"),\n",
    "        col(\"du.vehicle_model\").alias(\"driver_vehicle_model\"),\n",
    "        col(\"du.vehicle_year\").alias(\"driver_vehicle_year\"),\n",
    "        col(\"du.vehicle_color\").alias(\"driver_vehicle_color\"),\n",
    "        col(\"du.vehicle_license_plate\").alias(\"driver_vehicle_license_plate\"),\n",
    "        col(\"pu.full_name\").alias(\"passenger_name\"),\n",
    "        col(\"pu.email\").alias(\"passenger_email\"),\n",
    "        col(\"pu.phone_number\").alias(\"passenger_phone\"),\n",
    "        col(\"dp.method\").alias(\"payment_method\"),\n",
    "        col(\"dp.status\").alias(\"payment_status\")\n",
    "    )\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "fact_request_with_user_payment.orderBy(\"driver_name\").show(10)\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 1101135485542712,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "silver to gold",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
